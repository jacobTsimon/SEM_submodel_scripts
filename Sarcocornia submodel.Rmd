---
title: "SARCOCORNIA SUBMODEL"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#TITLE: Sarcocornia submodel script
#AUTHOR: Jacob Simon
#CONTACT: jts30437@uga.edu
#LAST UPDATED: 02/02/2022

#Function for calculating effective sample size from Moran's I and actual sample size
```{r effective-sample-size}
N.eff<-function(I,N){ #input values: Moran's I estimate, variable sample size
  result<-N*(1-I)/(1+I) #calculate n' using Cressie 2015's equation
  return(result)
}
```
#Function for calculating adjusted model parameters
```{r model-adjuster}
mod.adjuster<-function(mod,N.eff){ #input values: model object to be adjusted, n' value
  std.errors<-coef(summary(mod))[,2]
  estimates<-coef(summary(mod))[,1] #store standard errors and coefficient estimates of model
  
  N<-length(mod$fitted.values) #pull out variable sample size from model
  adj.index<-sqrt(N/N.eff)
  
  SE.adj<-std.errors*adj.index #adjust standard errors
  t.adj<-estimates/SE.adj
  p.adj<-2*pt(-abs(t.adj),df = N.eff - 1) #adjust p values using adjusted t values
  
  df.results<-data.frame(SE.adj,p.adj)
  return(df.results)
}
```
#Function for revising the dataframe to reflect spot-checked photos
```{r df-reviser}
df.reviser<-function(file,df,colnum = NA){  #function for revising datasets to reflect spot checked values
  
bot.rev<-read.delim(file = file)
int.mod<-df

print(paste("Number of false positives found:",sum(bot.rev[,3] == 0)))

if(is.na(colnum) == FALSE){
  print(paste("Number of positives in original dataframe:",sum(as.numeric(df[,colnum] > 0))))
}

for (i in 1:length(bot.rev[,1])) {
  response<-bot.rev[i,3]
  
  if (response != 0 & response != 1){
    print("mistakes were made")
    print(response)
    print(bot.rev[i,])
  }

  if (response == 0){
    row<-bot.rev[i,1]
    DSC<-bot.rev[i,2]
    
    
    for (j in 1:length(df[,1])) {
      ref.row<-df$Row
        ref.row<-ref.row[j]
      ref.DSC<-df$Image_Id
        ref.DSC<-ref.DSC[j]
      if (row == ref.row & DSC == ref.DSC){
        int.mod[j,colnum]<-response
      }
    }
  }
}
print(paste("Adjusted number of observations:", sum(as.numeric(int.mod[,colnum] > 0))))
  return(int.mod)
}
```
#Function for range adjusted coefficient calculation
```{r coef-stdizer}
range.std.coef<-function(PAmod,Pmod,data){ #takes presence/absence and abundance models for input, and the dataframe used for modelling
  PAcoef_names<-names(PAmod$coefficients)
    PAcoef_names<-PAcoef_names[-1]  #remove the intercept
  df_names<-names(data)
  
  PA_vars_stats<-matrix(ncol = length(PAcoef_names),nrow = 3)
  n<-0
for (h in 1:length(PAcoef_names)) {
  for (i in 1:length(df_names)) {
    if(df_names[i] == PAcoef_names[h]){
      n<-n + 1

      PA_vars_stats[1,n]<-mean(data[,i])  #stores the mean value of each predictor variable
      PA_vars_stats[2,n]<-min(data[,i])   #stores the min value
      PA_vars_stats[3,n]<-max(data[,i])   #stores the max value
      break
    }
  }
}
  
  Pcoef_names<-names(Pmod$coefficients)
    Pcoef_names<-Pcoef_names[-1]  #remove the intercept
  df_names<-names(data)
  
  P_vars_stats<-matrix(ncol = length(Pcoef_names),nrow = 3)
  
  m<-0
for (j in 1:length(Pcoef_names)) {
  for (k in 1:length(df_names)) {
    if(df_names[k] == Pcoef_names[j]){
      m<-m + 1
      
      P_vars_stats[1,m]<-mean(data[,k])  #stores the mean value of each predictor variable
      P_vars_stats[2,m]<-min(data[,k])   #stores the min value
      P_vars_stats[3,m]<-max(data[,k])   #stores the max value
      break
    }
  }
} 
  #find the range of the dependent variable in the models
  dep_var_name<-names(Pmod$model)[1] #use presence since PA is a binary dependent var
  for (b in 1:length(df_names)) {
    if(df_names[b] == dep_var_name){
      dep_var<-data[,b]
      
      var_range_vals<-range(data[,b])
      var_range<-var_range_vals[2] - var_range_vals[1]
      break
    }
  }  
  
#calculate max and min values for each predictor in the presence/absence model  
  PAcoef<-PAmod$coefficients
  PAmod_mean_vals<-c()
  PAmod_max_vals<-c()
  PAmod_min_vals<-c()
  
  for (z in 1:length(PAcoef_names)) {
    PAmod_mean_vals[z]<-PAcoef[z+1] * PA_vars_stats[1,z]
    PAmod_min_vals[z]<-PAcoef[z+1] * PA_vars_stats[2,z]
    PAmod_max_vals[z]<-PAcoef[z+1] * PA_vars_stats[3,z]
  }
#calculate max and min values for each predictor in the abundance model
  Pcoef<-Pmod$coefficients
  Pmod_mean_vals<-c()
  Pmod_max_vals<-c()
  Pmod_min_vals<-c()
  for (z in 1:length(Pcoef_names)) {
    Pmod_mean_vals[z]<-Pcoef[z+1] * P_vars_stats[1,z]
    Pmod_min_vals[z]<-Pcoef[z+1] * P_vars_stats[2,z]
    Pmod_max_vals[z]<-Pcoef[z+1] * P_vars_stats[3,z]
  }
  
##In the case of a model with differing sets of coefficients, different procedure is needed
 if ( length(Pcoef_names) != length(PAcoef_names)){ #test for difference
  
  if(length(PAcoef_names) > length(Pcoef_names)){#establish which model is longer
    long_list<-PAcoef_names
    id<-'PA'   #marker for later use
    alt.id<-'P'
    short_list<-Pcoef_names
  }
  else{
      long_list<-Pcoef_names
      short_list<-PAcoef_names
      id<-'P'
      alt.id<-'PA'
    }
  
  dupes<-match(x = long_list,short_list)  #find the positions of matching coefficients 
  dupeShort<-match(short_list,long_list)     
  
  
  #vectors to store calculated values
  max.toggle<-c()
  min.toggle<-c()
  diff.vec<-c()
  for (j in 1:length(dupes)) { #loop through the longer model
    if(is.na(dupes[j]) != TRUE){ #when this statement is TRUE, coef present in both models
      d<-dupes[j]
      if(id == 'PA'){ #a TRUE here indicates the presence/absence model is longer
        PAmax_toggle<-1/(1+1/(exp(PAcoef[1] + PAmod_max_vals[j] + sum(PAmod_mean_vals[-j]))))
        Pmax_toggle<-Pcoef[1] + Pmod_max_vals[d] + sum(Pmod_mean_vals[-d])
        
        PAmin_toggle<-1/(1+1/(exp(PAcoef[1] + PAmod_min_vals[j] + sum(PAmod_mean_vals[-j]))))
        Pmin_toggle<-Pcoef[1] + Pmod_min_vals[d] + sum(Pmod_mean_vals[-d])
        
        max.toggle[j]<-PAmax_toggle*Pmax_toggle
        min.toggle[j]<-PAmin_toggle*Pmin_toggle
        diff.vec[j]<-max.toggle[j] - min.toggle[j]
      }
      else{ #indicates that presence model is longer, so reverse the indexes
        Pmax_toggle<-Pcoef[1] + Pmod_max_vals[j] + sum(Pmod_mean_vals[-j])
        PAmax_toggle<-1/(1+1/(exp(PAcoef[1] + PAmod_max_vals[d] + sum(PAmod_mean_vals[-d]))))
        
        Pmin_toggle<-Pcoef[1] + Pmod_min_vals[j] + sum(Pmod_mean_vals[-j])
        PAmin_toggle<-1/(1+1/(exp(PAcoef[1] + PAmod_min_vals[d] + sum(PAmod_mean_vals[-d]))))
        
        max.toggle[j]<-PAmax_toggle*Pmax_toggle
        min.toggle[j]<-PAmin_toggle*Pmin_toggle
        diff.vec[j]<-max.toggle[j] - min.toggle[j]
      }
    }
  else{ #indicates that the coef is unique to the long model
    if(id == 'PA'){ #longer mod is PA
        PAmax_toggle<-1/(1+1/(exp(PAcoef[1] + PAmod_max_vals[j] + sum(PAmod_mean_vals[-j]))))
        Pmax_toggle<-Pcoef[1] + sum(Pmod_mean_vals) #no longer need to worry about max
        
        PAmin_toggle<-1/(1+1/(exp(PAcoef[1] + PAmod_min_vals[j] + sum(PAmod_mean_vals[-j]))))
        Pmin_toggle<-Pcoef[1] + sum(Pmod_mean_vals) # or mins
        
        max.toggle[j]<-PAmax_toggle*Pmax_toggle
        min.toggle[j]<-PAmin_toggle*Pmin_toggle
        diff.vec[j]<-max.toggle[j] - min.toggle[j]
      }
      else{ #the longer model is presence
        Pmax_toggle<-Pcoef[1] + Pmod_max_vals[j] + sum(Pmod_mean_vals[-j])
        PAmax_toggle<-1/(1+1/(exp(PAcoef[1] + sum(PAmod_mean_vals))))
        
        Pmin_toggle<-Pcoef[1] + Pmod_min_vals[j] + sum(Pmod_mean_vals[-j])
        PAmin_toggle<-1/(1+1/(exp(PAcoef[1] + sum(PAmod_mean_vals))))
        
        max.toggle[j]<-PAmax_toggle*Pmax_toggle
        min.toggle[j]<-PAmin_toggle*Pmin_toggle
        diff.vec[j]<-max.toggle[j] - min.toggle[j]
      }
  }  
  }
  #separate vectors for the short model coef
  max.toggleS<-c()
  min.toggleS<-c()
  diff.vecS<-c()
  for (j in 1:length(dupeShort)) { #this one loops through the shorter length mod
    if(is.na(dupeShort[j]) != TRUE){#TRUE here indicates coefficient is present in both mods
      d<-dupeShort[j]
      if(id != 'PA'){ #PA is shorter (switched the logic, kept indexing the same)
        PAmax_toggle<-1/(1+1/(exp(PAcoef[1] + PAmod_max_vals[j] + sum(PAmod_mean_vals[-j]))))
        Pmax_toggle<-Pcoef[1] + Pmod_max_vals[d] + sum(Pmod_mean_vals[-d])
        
        PAmin_toggle<-1/(1+1/(exp(PAcoef[1] + PAmod_min_vals[j] + sum(PAmod_mean_vals[-j]))))
        Pmin_toggle<-Pcoef[1] + Pmod_min_vals[d] + sum(Pmod_mean_vals[-d])
        
        max.toggleS[j]<-PAmax_toggle*Pmax_toggle
        min.toggleS[j]<-PAmin_toggle*Pmin_toggle
        diff.vecS[j]<-max.toggleS[j] - min.toggleS[j]
      }
      else{ #P is shorter
        Pmax_toggle<-Pcoef[1] + Pmod_max_vals[j] + sum(Pmod_mean_vals[-j])
        PAmax_toggle<-1/(1+1/(exp(PAcoef[1] + PAmod_max_vals[d] + sum(PAmod_mean_vals[-d]))))
        
        Pmin_toggle<-Pcoef[1] + Pmod_min_vals[j] + sum(Pmod_mean_vals[-j])
        PAmin_toggle<-1/(1+1/(exp(PAcoef[1] + PAmod_min_vals[d] + sum(PAmod_mean_vals[-d]))))
        
        max.toggleS[j]<-PAmax_toggle*Pmax_toggle
        min.toggleS[j]<-PAmin_toggle*Pmin_toggle
        diff.vecS[j]<-max.toggleS[j] - min.toggleS[j]
      }
    }
    else{ #coef is unique to the shorter model
    if(id != 'PA'){ #PA is shorter
        PAmax_toggle<-1/(1+1/(exp(PAcoef[1] + PAmod_max_vals[j] + sum(PAmod_mean_vals[-j]))))
        Pmax_toggle<-Pcoef[1] + sum(Pmod_mean_vals)
        
        PAmin_toggle<-1/(1+1/(exp(PAcoef[1] + PAmod_min_vals[j] + sum(PAmod_mean_vals[-j]))))
        Pmin_toggle<-Pcoef[1] + sum(Pmod_mean_vals)
        
        max.toggleS[j]<-PAmax_toggle*Pmax_toggle
        min.toggleS[j]<-PAmin_toggle*Pmin_toggle
        diff.vecS[j]<-max.toggleS[j] - min.toggleS[j]
      }
      else{ #P is shorter
        Pmax_toggle<-Pcoef[1] + Pmod_max_vals[j] + sum(Pmod_mean_vals[-j])
        PAmax_toggle<-1/(1+1/(exp(PAcoef[1] + sum(PAmod_mean_vals))))
        
        Pmin_toggle<-Pcoef[1] + Pmod_min_vals[j] + sum(Pmod_mean_vals[-j])
        PAmin_toggle<-1/(1+1/(exp(PAcoef[1] + sum(PAmod_mean_vals))))
        
        max.toggleS[j]<-PAmax_toggle*Pmax_toggle
        min.toggleS[j]<-PAmin_toggle*Pmin_toggle
        diff.vecS[j]<-max.toggleS[j] - min.toggleS[j]
        }
      }
  }  
  #divide by the variable's range to gain a vector of standardized coefficients
  std_long<-diff.vec/var_range
  std_short<-diff.vecS/var_range
  
  #put together cohesive object for return value
  long_name<-paste(id," model std coef")
  short_name<-paste(alt.id," model std coef")
  
  std_long<-data.frame(std_long,row.names = long_list)
    colnames(std_long)<-long_name
    
  std_short<-data.frame(std_short,row.names = short_list)
    colnames(std_short)<-short_name
  
  print(paste(long_list,"long mod:",max.toggle,min.toggle))
  print(paste(short_list,"short mod:",max.toggleS,min.toggleS))
  print(paste(long_list,"long mod:", std_long))
  print(paste(short_list, "short model:",std_short))
  
  result<-list(std_long,std_short)
    names(result)<-c(long_name,short_name)
  
  return(result)
     }

  #this code can carry out the simpler case of models with the same coefficients
  
  PAmax_toggle<-c()  #create vectors for maximum/minimum values of presence/absence model
  PAmin_toggle<-c()
  for (y in 1:length(PA_vars_stats[1,])) {
    PAmax_toggle[y]<-1/(1+1/(exp(PAcoef[1] + PAmod_max_vals[y] + sum(PAmod_mean_vals[-y]))))#need to transform from logit
    PAmin_toggle[y]<-1/(1+1/(exp(PAcoef[1] + PAmod_min_vals[y] + sum(PAmod_mean_vals[-y]))))
  }
  
  Pmax_toggle<-c()   #create vectors for maximum/minimum values of presence/absence model
  Pmin_toggle<-c()
  for (y in 1:length(P_vars_stats[1,])) {
    Pmax_toggle[y]<-Pcoef[1] + Pmod_max_vals[y] + sum(Pmod_mean_vals[-y])
    Pmin_toggle[y]<-Pcoef[1] + Pmod_min_vals[y] + sum(Pmod_mean_vals[-y])
  }
  #calculate the combined max/min toggles 
  max_toggle<-PAmax_toggle * Pmax_toggle
  min_toggle<-PAmin_toggle * Pmin_toggle
  
  #calculate the full model mean, and print it alongsidde dependent variable mean
  full_mod_mean<-(Pcoef[1] + sum(Pmod_mean_vals)) * 1/(1+1/(exp((PAcoef[1] + sum(PAmod_mean_vals)))))
  print(paste("Model mean:",signif(full_mod_mean,digits = 5))) #calculate and report the mean
  print(paste("Dependent Var. Mean: ",mean(dep_var)))
  
  diff_vector<-max_toggle - min_toggle  #take the difference between maximum and minimum toggle
  stdized_vector<-diff_vector/var_range #divide by variable range
    
  
  
    for (p in seq(length(stdized_vector))) { #print each of the standardized coefficients
      print(paste(PAcoef_names[p],"=",signif(stdized_vector[p],digits = 5),"(Range standardized)"))
    }
  
  result<-rbind(PAcoef_names,stdized_vector) #cohesive table to be returned
  
  return(result)
}
```

#SPOT CHECK
```#{r range-std-coef-check}
#PA coefficients
PA_int<- -20.7871
PA_elev<-24.05471
PA_sal<-0.07569937
PA_junc<- -0.01330433

#P coefficients
P_int<- 0.8701559
P_elev<-1.677092
P_sal<-0.003548338
P_junc<- -0.04750894

#mean values of predictors
mean_elev<-mean(CNNdata$elevation..m.)
mean_sal<-mean(CNNdata$salinity..psu.)
mean_junc<-mean(CNNdata$Juncus)
#max values of predictors
max_elev<-max(CNNdata$elevation..m.)
max_sal<-max(CNNdata$salinity..psu.)
max_junc<-max(CNNdata$Juncus)
#min values of predictors
min_elev<-min(CNNdata$elevation..m.)
min_sal<-min(CNNdata$salinity..psu.)
min_junc<-min(CNNdata$Juncus)
#range of dependent var
range_sarc<-range(CNNdata$logSarc)
  Range_sarc<-range_sarc[2] - range_sarc[1]

#whole model mean
WMM<- (1/(1+1/(exp(PA_int + PA_elev*mean_elev + PA_sal*mean_sal + PA_junc*mean_junc))))*(P_int + P_elev*mean_elev + P_sal*mean_sal + P_junc*mean_junc)
#matches fairly well!

#max/min toggling
elevMAXtoggle<-(1/(1+1/(exp(PA_int + PA_elev*max_elev + PA_sal*mean_sal + PA_junc*mean_junc))))*(P_int + P_elev*max_elev + P_sal*mean_sal + P_junc*mean_junc)
elevMINtoggle<-(1/(1+1/(exp(PA_int + PA_elev*min_elev + PA_sal*mean_sal + PA_junc*mean_junc))))*(P_int + P_elev*min_elev + P_sal*mean_sal + P_junc*mean_junc)
elevDIFF<- elevMAXtoggle - elevMINtoggle
elevSTD<- elevDIFF/Range_sarc
print(elevSTD)
#sal
salMAXtoggle<-(1/(1+1/(exp(PA_int + PA_elev*mean_elev + PA_sal*max_sal + PA_junc*mean_junc))))*(P_int + P_elev*mean_elev + P_sal*max_sal + P_junc*mean_junc)
salMINtoggle<-(1/(1+1/(exp(PA_int + PA_elev*mean_elev + PA_sal*min_sal + PA_junc*mean_junc))))*(P_int + P_elev*mean_elev + P_sal*min_sal + P_junc*mean_junc)
salDIFF<-salMAXtoggle - salMINtoggle
salSTD<-salDIFF/Range_sarc
print(salSTD)
#junc
juncMAXtoggle<-(1/(1+1/(exp(PA_int + PA_elev*mean_elev + PA_sal*mean_sal + PA_junc*max_junc))))*(P_int + P_elev*mean_elev + P_sal*mean_sal + P_junc*max_junc)
juncMINtoggle<-(1/(1+1/(exp(PA_int + PA_elev*mean_elev + PA_sal*mean_sal + PA_junc*min_junc))))*(P_int + P_elev*mean_elev + P_sal*mean_sal + P_junc*min_junc)
juncDIFF<- juncMAXtoggle - juncMINtoggle
juncSTD<-juncDIFF/Range_sarc
print(juncSTD)
```

#SARCOCORNIA submodel
```{r data-read-in}
#this load method is relative to the working directory - adjust your files as needed
preCNNdata<-read.csv("2014_plants_snail_xy_data.csv")
  preCNNdata<-na.omit(preCNNdata)
```
#read in revised data and replace values
```{r}
CNNdata<-df.reviser('BatisCheck.txt',preCNNdata,12)  #use column 12 for Batis (this is all dataframe dependent)
CNNdata<-df.reviser('SpartCheck.txt',CNNdata,9)  #use column 9 for Spartina
CNNdata<-df.reviser('LimoCheck.txt',CNNdata,10)  #use column 10 for Limonium
CNNdata<-df.reviser('BorrCheck.txt',CNNdata,11)  #use column 11 for Borr
CNNdata<-df.reviser('JuncCheck.txt',CNNdata,13)  #use column 13 for Juncus
CNNdata<-df.reviser('SarcCheck.txt',CNNdata,8)  #use column 8 for Sarcocornia
```
#create a marker for the nonhospitable habitat (salt pan in the site interior)
```{r saltpan-marker}
saltpan<-ifelse(CNNdata$Spart==0 & CNNdata$Sarc==0 & CNNdata$Limon==0 & CNNdata$Batis==0 & CNNdata$Bor==0 & CNNdata$Juncus==0 & CNNdata$salinity..psu.>60, 1,0)
#append these markers to our data frame
CNNdata$saltpanYN<-saltpan
```
#Establish a lower elevation threshold for Sarcocornia
```{r sarc-thresh}
sarc.thresh<-ifelse(CNNdata$Sarc==0 & CNNdata$elevation..m. < 0.55,1,0)
  #1781 observations below Sarcocornia's flooding limit (or perhaps just in the Spartina zone)

#place the threshold marker in the dataset
CNNdata$sarcthreshYN<-sarc.thresh  #here 0 indicates hospitable habitat
```
#subset the sarc data
```{r}
#first put in present/absence and log transformed columns
CNNdata$sarcPA<-ifelse(CNNdata$Sarc>0,1,0)
CNNdata$logSarc<-log1p(CNNdata$Sarc)
#now split the data sets
sarc.hab<-subset(CNNdata,saltpanYN==0 & sarcthreshYN == 0) 
sarc.inhosp<-rbind(subset(CNNdata,saltpanYN==1),subset(CNNdata,sarcthreshYN == 1)) 
#sum to 9278, shouldn't be any overlap 
sum(length(sarc.hab[,1]),length(sarc.inhosp[,1]))
```
#conduct logistic regression on the PA data with the hospitable habitat df
```{r}
sarcPAmod1<-glm(sarcPA~elevation..m. + Juncus + Bor + salinity..psu.,family = 'binomial',data = sarc.hab)

library(MASS)
sarcStep<-stepAIC(sarcPAmod1,direction = "both")
sarcStep$anova

#initial model selected
```

```{r}
#view selected model
summary(sarcPAmod1)

#store presence/absence model residuals
PA.resid<-resid(sarcPAmod1)
```
#conduct loglinear regression on positive sarcocornia values
```{r}
sarc.habY<-subset(sarc.hab,sarcPA==1)  #create a df for only rows w/ Sarcocornia present

sarcPmod1<-lm(logSarc~elevation..m. + Juncus + Bor + salinity..psu.,data = sarc.habY)

sarcStep2<-stepAIC(sarcPmod1,direction = "both")
sarcStep2$anova

#initial model selected
```
```{r algorithm-check}
#test out saturated stepwise selection
sat.sarcPAmod<-glm(sarcPA~elevation..m. + salinity..psu. + Juncus + Bor + Spart + Batis,data = sarc.hab)

satStep<-stepAIC(sat.sarcPAmod,direction = 'both')
satStep$anova
```

```{r}
#view selected model
summary(sarcPmod1)

#store abundance model residuals
P.resid<-resid(sarcPmod1)
```
#conduct spatial autocorrelation correction on both models
```{r}
library(spdep) #library the spatial dependance package

#carry out the Moran's I estimation for both models
PAxy.data<-cbind(sarc.hab$easting..m.,sarc.hab$northing..m.)
Pxy.data<-cbind(sarc.habY$easting..m.,sarc.habY$northing..m.)

PAxy.knn<-knearneigh(PAxy.data,k = 4)
PAxy.nb<-knn2nb(PAxy.knn)

Pxy.knn<-knearneigh(Pxy.data,k = 4)
Pxy.nb<-knn2nb(Pxy.knn)

PA.sarc.Moran<-moran.test(PA.resid,nb2listw(PAxy.nb,style ="W"))
P.sarc.Moran<-moran.test(P.resid,nb2listw(Pxy.nb,style ="W"))
```

#compute adjusted sample size, standard errors and p values
```{r}
PAsarcNeff<-as.numeric(N.eff(PA.sarc.Moran$estimate[1],length(sarc.hab[,1]))) #calculate n' for each model using function written above
PsarcNeff<-as.numeric(N.eff(P.sarc.Moran$estimate[1],length(sarc.habY[,1])))
#n' values added to column 3 & 4 of Table 2

mod.adjuster(sarcPAmod1,PAsarcNeff) #adjust each model and print values
mod.adjuster(sarcPmod1,PsarcNeff)

#evaluate p values for increases above 0.05
```

#capture predictions for both models
```{r}
#create objects for loglinear prediction equation
elev<-sarc.habY$elevation..m.
Junc<-sarc.habY$Juncus
Bor<-sarc.habY$Bor
sal<-sarc.habY$salinity..psu.

LLpred<- -0.0978753 + 2.9727715*elev - 0.0472671*Junc - 0.0659330*Bor + 0.0044713*sal

sarc.hab$sarcLMpred<-0   
n<-0
for (i in 1:length(sarc.hab[,1])) {   #index in the LM productivity estimates to sarc.hab
  test<-sarc.hab$logSarc[i]
  if(test > 0 ){ #productivity estimate is zero where not present
    n<-n+1
    
    sarc.hab$sarcLMpred[i]<-LLpred[n]  
  }
}

#get logistic predictions from model
sarc.hab$sarcLOGpred<-predict(sarcPAmod1,type = "response")

#insert 0 predictions for each value in the salt pan & below the elevation threshold
sarc.inhosp$sarcLOGpred<-0
sarc.inhosp$sarcLMpred<-0
```
#Continuing as directed in the Schwieger R code, may need to amend to reflect updates
```{r}
#bind the two dataframes together, and create a cohesive prediction value column
sarc.merge<-rbind(sarc.hab,sarc.inhosp)

sarc.merge$sarcPRED<-sarc.merge$sarcLOGpred*sarc.merge$sarcLMpred
```
#regress our cohesive predictive value against the observed value
```{r}
sarcFmod<-lm(sarc.merge$logSarc ~ sarc.merge$sarcPRED)

summary(sarcFmod)

#store R^2 value
sarcR2<-summary(sarcFmod)$r.squared
sarcR2adj<-summary(sarcFmod)$adj.r.squared
```
# standardize the final model coefficients
```{r}
sarc_coef<-range.std.coef(sarcPAmod1,sarcPmod1,CNNdata)#calculate final range standardized coefficients
print(sarc_coef)
```
