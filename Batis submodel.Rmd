---
title: "BATIS SUBMODEL"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#TITLE: Batis submodel script
#AUTHOR: Jacob Simon
#CONTACT: jts30437@uga.edu
#LAST UPDATED: 02/02/2022

#Function for calculating effective sample size from Moran's I and actual sample size
```{r effective-sample-size}
N.eff<-function(I,N){ #input values: Moran's I estimate, variable sample size
  result<-N*(1-I)/(1+I) #calculate n' using Cressie 2015's equation
  return(result)
}
```
#Function for calculating adjusted model parameters
```{r model-adjuster}
mod.adjuster<-function(mod,N.eff){ #input values: model object to be adjusted, n' value
  std.errors<-coef(summary(mod))[,2]
  estimates<-coef(summary(mod))[,1] #store standard errors and coefficient estimates of model
  
  N<-length(mod$fitted.values) #pull out variable sample size from model
  adj.index<-sqrt(N/N.eff)
  
  SE.adj<-std.errors*adj.index #adjust standard errors
  t.adj<-estimates/SE.adj
  p.adj<-2*pt(-abs(t.adj),df = N.eff - 1) #adjust p values using adjusted t values
  
  df.results<-data.frame(SE.adj,p.adj)
  return(df.results)
}
```
#Function for revising the dataframe to reflect spot-checked photos
```{r df-reviser}
df.reviser<-function(file,df,colnum = NA){  #function for revising datasets to reflect spot checked values
  
bot.rev<-read.delim(file = file)
int.mod<-df

print(paste("Number of false positives found:",sum(bot.rev[,3] == 0)))

if(is.na(colnum) == FALSE){
  print(paste("Number of positives in original dataframe:",sum(as.numeric(df[,colnum] > 0))))
}

for (i in 1:length(bot.rev[,1])) {
  response<-bot.rev[i,3]
  
  if (response != 0 & response != 1){
    print("mistakes were made")
    print(response)
    print(bot.rev[i,])
  }

  if (response == 0){
    row<-bot.rev[i,1]
    DSC<-bot.rev[i,2]
    
    
    for (j in 1:length(df[,1])) {
      ref.row<-df$Row
        ref.row<-ref.row[j]
      ref.DSC<-df$Image_Id
        ref.DSC<-ref.DSC[j]
      if (row == ref.row & DSC == ref.DSC){
        int.mod[j,colnum]<-response
      }
    }
  }
}
print(paste("Adjusted number of observations:", sum(as.numeric(int.mod[,colnum] > 0))))
  return(int.mod)
}
```
#Function for range adjusted coefficient calculation
```{r coef-stdizer}
range.std.coef<-function(PAmod,Pmod,data){ #takes presence/absence and abundance models for input, and the dataframe used for modelling
  PAcoef_names<-names(PAmod$coefficients)
    PAcoef_names<-PAcoef_names[-1]  #remove the intercept
  df_names<-names(data)
  
  PA_vars_stats<-matrix(ncol = length(PAcoef_names),nrow = 3)
  n<-0
for (h in 1:length(PAcoef_names)) {
  for (i in 1:length(df_names)) {
    if(df_names[i] == PAcoef_names[h]){
      n<-n + 1

      PA_vars_stats[1,n]<-mean(data[,i])  #stores the mean value of each predictor variable
      PA_vars_stats[2,n]<-min(data[,i])   #stores the min value
      PA_vars_stats[3,n]<-max(data[,i])   #stores the max value
      break
    }
  }
}
  
  Pcoef_names<-names(Pmod$coefficients)
    Pcoef_names<-Pcoef_names[-1]  #remove the intercept
  df_names<-names(data)
  
  P_vars_stats<-matrix(ncol = length(Pcoef_names),nrow = 3)
  
  m<-0
for (j in 1:length(Pcoef_names)) {
  for (k in 1:length(df_names)) {
    if(df_names[k] == Pcoef_names[j]){
      m<-m + 1
      
      P_vars_stats[1,m]<-mean(data[,k])  #stores the mean value of each predictor variable
      P_vars_stats[2,m]<-min(data[,k])   #stores the min value
      P_vars_stats[3,m]<-max(data[,k])   #stores the max value
      break
    }
  }
} 
  #find the range of the dependent variable in the models
  dep_var_name<-names(Pmod$model)[1] #use presence since PA is a binary dependent var
  for (b in 1:length(df_names)) {
    if(df_names[b] == dep_var_name){
      dep_var<-data[,b]
      
      var_range_vals<-range(data[,b])
      var_range<-var_range_vals[2] - var_range_vals[1]
      break
    }
  }  
  
#calculate max and min values for each predictor in the presence/absence model  
  PAcoef<-PAmod$coefficients
  PAmod_mean_vals<-c()
  PAmod_max_vals<-c()
  PAmod_min_vals<-c()
  
  for (z in 1:length(PAcoef_names)) {
    PAmod_mean_vals[z]<-PAcoef[z+1] * PA_vars_stats[1,z]
    PAmod_min_vals[z]<-PAcoef[z+1] * PA_vars_stats[2,z]
    PAmod_max_vals[z]<-PAcoef[z+1] * PA_vars_stats[3,z]
  }
#calculate max and min values for each predictor in the abundance model
  Pcoef<-Pmod$coefficients
  Pmod_mean_vals<-c()
  Pmod_max_vals<-c()
  Pmod_min_vals<-c()
  for (z in 1:length(Pcoef_names)) {
    Pmod_mean_vals[z]<-Pcoef[z+1] * P_vars_stats[1,z]
    Pmod_min_vals[z]<-Pcoef[z+1] * P_vars_stats[2,z]
    Pmod_max_vals[z]<-Pcoef[z+1] * P_vars_stats[3,z]
  }
  
##In the case of a model with differing sets of coefficients, different procedure is needed
 if ( length(Pcoef_names) != length(PAcoef_names)){ #test for difference
  
  if(length(PAcoef_names) > length(Pcoef_names)){#establish which model is longer
    long_list<-PAcoef_names
    id<-'PA'   #marker for later use
    alt.id<-'P'
    short_list<-Pcoef_names
  }
  else{
      long_list<-Pcoef_names
      short_list<-PAcoef_names
      id<-'P'
      alt.id<-'PA'
    }
  
  dupes<-match(x = long_list,short_list)  #find the positions of matching coefficients 
  dupeShort<-match(short_list,long_list)     
  
  
  #vectors to store calculated values
  max.toggle<-c()
  min.toggle<-c()
  diff.vec<-c()
  for (j in 1:length(dupes)) { #loop through the longer model
    if(is.na(dupes[j]) != TRUE){ #when this statement is TRUE, coef present in both models
      d<-dupes[j]
      if(id == 'PA'){ #a TRUE here indicates the presence/absence model is longer
        PAmax_toggle<-1/(1+1/(exp(PAcoef[1] + PAmod_max_vals[j] + sum(PAmod_mean_vals[-j]))))
        Pmax_toggle<-Pcoef[1] + Pmod_max_vals[d] + sum(Pmod_mean_vals[-d])
        
        PAmin_toggle<-1/(1+1/(exp(PAcoef[1] + PAmod_min_vals[j] + sum(PAmod_mean_vals[-j]))))
        Pmin_toggle<-Pcoef[1] + Pmod_min_vals[d] + sum(Pmod_mean_vals[-d])
        
        max.toggle[j]<-PAmax_toggle*Pmax_toggle
        min.toggle[j]<-PAmin_toggle*Pmin_toggle
        diff.vec[j]<-max.toggle[j] - min.toggle[j]
      }
      else{ #indicates that presence model is longer, so reverse the indexes
        Pmax_toggle<-Pcoef[1] + Pmod_max_vals[j] + sum(Pmod_mean_vals[-j])
        PAmax_toggle<-1/(1+1/(exp(PAcoef[1] + PAmod_max_vals[d] + sum(PAmod_mean_vals[-d]))))
        
        Pmin_toggle<-Pcoef[1] + Pmod_min_vals[j] + sum(Pmod_mean_vals[-j])
        PAmin_toggle<-1/(1+1/(exp(PAcoef[1] + PAmod_min_vals[d] + sum(PAmod_mean_vals[-d]))))
        
        max.toggle[j]<-PAmax_toggle*Pmax_toggle
        min.toggle[j]<-PAmin_toggle*Pmin_toggle
        diff.vec[j]<-max.toggle[j] - min.toggle[j]
      }
    }
  else{ #indicates that the coef is unique to the long model
    if(id == 'PA'){ #longer mod is PA
        PAmax_toggle<-1/(1+1/(exp(PAcoef[1] + PAmod_max_vals[j] + sum(PAmod_mean_vals[-j]))))
        Pmax_toggle<-Pcoef[1] + sum(Pmod_mean_vals) #no longer need to worry about max
        
        PAmin_toggle<-1/(1+1/(exp(PAcoef[1] + PAmod_min_vals[j] + sum(PAmod_mean_vals[-j]))))
        Pmin_toggle<-Pcoef[1] + sum(Pmod_mean_vals) # or mins
        
        max.toggle[j]<-PAmax_toggle*Pmax_toggle
        min.toggle[j]<-PAmin_toggle*Pmin_toggle
        diff.vec[j]<-max.toggle[j] - min.toggle[j]
      }
      else{ #the longer model is presence
        Pmax_toggle<-Pcoef[1] + Pmod_max_vals[j] + sum(Pmod_mean_vals[-j])
        PAmax_toggle<-1/(1+1/(exp(PAcoef[1] + sum(PAmod_mean_vals))))
        
        Pmin_toggle<-Pcoef[1] + Pmod_min_vals[j] + sum(Pmod_mean_vals[-j])
        PAmin_toggle<-1/(1+1/(exp(PAcoef[1] + sum(PAmod_mean_vals))))
        
        max.toggle[j]<-PAmax_toggle*Pmax_toggle
        min.toggle[j]<-PAmin_toggle*Pmin_toggle
        diff.vec[j]<-max.toggle[j] - min.toggle[j]
      }
  }  
  }
  #separate vectors for the short model coef
  max.toggleS<-c()
  min.toggleS<-c()
  diff.vecS<-c()
  for (j in 1:length(dupeShort)) { #this one loops through the shorter length mod
    if(is.na(dupeShort[j]) != TRUE){#TRUE here indicates coefficient is present in both mods
      d<-dupeShort[j]
      if(id != 'PA'){ #PA is shorter (switched the logic, kept indexing the same)
        PAmax_toggle<-1/(1+1/(exp(PAcoef[1] + PAmod_max_vals[j] + sum(PAmod_mean_vals[-j]))))
        Pmax_toggle<-Pcoef[1] + Pmod_max_vals[d] + sum(Pmod_mean_vals[-d])
        
        PAmin_toggle<-1/(1+1/(exp(PAcoef[1] + PAmod_min_vals[j] + sum(PAmod_mean_vals[-j]))))
        Pmin_toggle<-Pcoef[1] + Pmod_min_vals[d] + sum(Pmod_mean_vals[-d])
        
        max.toggleS[j]<-PAmax_toggle*Pmax_toggle
        min.toggleS[j]<-PAmin_toggle*Pmin_toggle
        diff.vecS[j]<-max.toggleS[j] - min.toggleS[j]
      }
      else{ #P is shorter
        Pmax_toggle<-Pcoef[1] + Pmod_max_vals[j] + sum(Pmod_mean_vals[-j])
        PAmax_toggle<-1/(1+1/(exp(PAcoef[1] + PAmod_max_vals[d] + sum(PAmod_mean_vals[-d]))))
        
        Pmin_toggle<-Pcoef[1] + Pmod_min_vals[j] + sum(Pmod_mean_vals[-j])
        PAmin_toggle<-1/(1+1/(exp(PAcoef[1] + PAmod_min_vals[d] + sum(PAmod_mean_vals[-d]))))
        
        max.toggleS[j]<-PAmax_toggle*Pmax_toggle
        min.toggleS[j]<-PAmin_toggle*Pmin_toggle
        diff.vecS[j]<-max.toggleS[j] - min.toggleS[j]
      }
    }
    else{ #coef is unique to the shorter model
    if(id != 'PA'){ #PA is shorter
        PAmax_toggle<-1/(1+1/(exp(PAcoef[1] + PAmod_max_vals[j] + sum(PAmod_mean_vals[-j]))))
        Pmax_toggle<-Pcoef[1] + sum(Pmod_mean_vals)
        
        PAmin_toggle<-1/(1+1/(exp(PAcoef[1] + PAmod_min_vals[j] + sum(PAmod_mean_vals[-j]))))
        Pmin_toggle<-Pcoef[1] + sum(Pmod_mean_vals)
        
        max.toggleS[j]<-PAmax_toggle*Pmax_toggle
        min.toggleS[j]<-PAmin_toggle*Pmin_toggle
        diff.vecS[j]<-max.toggleS[j] - min.toggleS[j]
      }
      else{ #P is shorter
        Pmax_toggle<-Pcoef[1] + Pmod_max_vals[j] + sum(Pmod_mean_vals[-j])
        PAmax_toggle<-1/(1+1/(exp(PAcoef[1] + sum(PAmod_mean_vals))))
        
        Pmin_toggle<-Pcoef[1] + Pmod_min_vals[j] + sum(Pmod_mean_vals[-j])
        PAmin_toggle<-1/(1+1/(exp(PAcoef[1] + sum(PAmod_mean_vals))))
        
        max.toggleS[j]<-PAmax_toggle*Pmax_toggle
        min.toggleS[j]<-PAmin_toggle*Pmin_toggle
        diff.vecS[j]<-max.toggleS[j] - min.toggleS[j]
        }
      }
  }  
  #divide by the variable's range to gain a vector of standardized coefficients
  std_long<-diff.vec/var_range
  std_short<-diff.vecS/var_range
  
  #put together cohesive object for return value
  long_name<-paste(id," model std coef")
  short_name<-paste(alt.id," model std coef")
  
  std_long<-data.frame(std_long,row.names = long_list)
    colnames(std_long)<-long_name
    
  std_short<-data.frame(std_short,row.names = short_list)
    colnames(std_short)<-short_name
  
  print(paste(long_list,"long mod:",max.toggle,min.toggle))
  print(paste(short_list,"short mod:",max.toggleS,min.toggleS))
  print(paste(long_list,"long mod:", std_long))
  print(paste(short_list, "short model:",std_short))
  
  result<-list(std_long,std_short)
    names(result)<-c(long_name,short_name)
  
  return(result)
     }

  #this code can carry out the simpler case of models with the same coefficients
  
  PAmax_toggle<-c()  #create vectors for maximum/minimum values of presence/absence model
  PAmin_toggle<-c()
  for (y in 1:length(PA_vars_stats[1,])) {
    PAmax_toggle[y]<-1/(1+1/(exp(PAcoef[1] + PAmod_max_vals[y] + sum(PAmod_mean_vals[-y]))))#need to transform from logit
    PAmin_toggle[y]<-1/(1+1/(exp(PAcoef[1] + PAmod_min_vals[y] + sum(PAmod_mean_vals[-y]))))
  }
  
  Pmax_toggle<-c()   #create vectors for maximum/minimum values of presence/absence model
  Pmin_toggle<-c()
  for (y in 1:length(P_vars_stats[1,])) {
    Pmax_toggle[y]<-Pcoef[1] + Pmod_max_vals[y] + sum(Pmod_mean_vals[-y])
    Pmin_toggle[y]<-Pcoef[1] + Pmod_min_vals[y] + sum(Pmod_mean_vals[-y])
  }
  #calculate the combined max/min toggles 
  max_toggle<-PAmax_toggle * Pmax_toggle
  min_toggle<-PAmin_toggle * Pmin_toggle
  
  #calculate the full model mean, and print it alongsidde dependent variable mean
  full_mod_mean<-(Pcoef[1] + sum(Pmod_mean_vals)) * 1/(1+1/(exp((PAcoef[1] + sum(PAmod_mean_vals)))))
  print(paste("Model mean:",signif(full_mod_mean,digits = 5))) #calculate and report the mean
  print(paste("Dependent Var. Mean: ",mean(dep_var)))
  
  diff_vector<-max_toggle - min_toggle  #take the difference between maximum and minimum toggle
  stdized_vector<-diff_vector/var_range #divide by variable range
    
  
  
    for (p in seq(length(stdized_vector))) { #print each of the standardized coefficients
      print(paste(PAcoef_names[p],"=",signif(stdized_vector[p],digits = 5),"(Range standardized)"))
    }
  
  result<-rbind(PAcoef_names,stdized_vector) #cohesive table to be returned
  
  return(result)
}
```

#BATIS submodel
```{r data-read-in}
#this load method is relative to the working directory - adjust your files as needed
preCNNdata<-read.csv("2014_plants_snail_xy_data.csv")
  preCNNdata<-na.omit(preCNNdata)
```
#read in revised data and replace values
```{r}
CNNdata<-df.reviser('BatisCheck.txt',preCNNdata,12)  #use column 12 for Batis (this is all dataframe dependent)
CNNdata<-df.reviser('SpartCheck.txt',CNNdata,9)  #use column 9 for Spartina
CNNdata<-df.reviser('LimoCheck.txt',CNNdata,10)  #use column 10 for Limonium
CNNdata<-df.reviser('BorrCheck.txt',CNNdata,11)  #use column 11 for Borr
CNNdata<-df.reviser('JuncCheck.txt',CNNdata,13)  #use column 13 for Juncus
CNNdata<-df.reviser('SarcCheck.txt',CNNdata,8)  #use column 8 for Sarcocornia
```
#create a marker for the nonhospitable habitat (salt pan in the site interior)
```{r saltpan-marker}
#make a marker column for points in which no species are present and salinity is high
saltpan<-ifelse(CNNdata$Spart==0 & CNNdata$Sarc==0 & CNNdata$Limon==0 & CNNdata$Batis==0 & CNNdata$Bor==0 & CNNdata$Juncus==0 & CNNdata$salinity..psu.>60, 1,0)
#append these markers to our data frame
CNNdata$saltpanYN<-saltpan
```

##construct the Batis submodel proper
```{r}
#lower elevation threshold for Batis
batis.thresh<-ifelse(CNNdata$Batis == 0 & CNNdata$elevation..m. < 0.66 & CNNdata$saltpanYN == 0, 1, 0)
#there are 3 instances of Batis presence below 0.66 m elevation (need to investigate this)

CNNdata$batisthreshYN<-batis.thresh  #here also, 0 indicates hospitable habitat
```
#insert PA/log abundance columns and subset
```{r}
CNNdata$batisPA<-ifelse(CNNdata$Batis > 0,1,0)
CNNdata$logBatis<-log1p(CNNdata$Batis)
#now subset the dataframe
batis.hab<-subset(CNNdata,batisthreshYN == 0 & saltpanYN == 0)
batis.inhosp<-rbind(subset(CNNdata,batisthreshYN == 1),subset(CNNdata, saltpanYN == 1))
#sum to 9278?
sum(length(batis.hab[,1]),length(batis.inhosp[,1]))
#above 9278, circle back and add logic for saltpanYN
```
#conduct logistic regression on the PA data with the hospitable habitat df
```{r}
batisPAmod1<-glm(batisPA ~ elevation..m. + salinity..psu. + Juncus + Bor,family = 'binomial',data = batis.hab)

library(MASS)
batisStep<-stepAIC(batisPAmod1,direction = "both")
batisStep$anova

#initial model selected
```

```{r}
#view selected model
summary(batisPAmod1)

#grab residuals for Moran's I testing
PA.resid<-resid(batisPAmod1)
```
#conduct loglinear regression on positive sarcocornia values
```{r}
batis.habY<-subset(batis.hab,batisPA==1)  #create a df for only obs where Batis is present

batisPmod1<-lm(logBatis~elevation..m. + salinity..psu. + Juncus + Bor,data = batis.habY)

batisStep2<-stepAIC(batisPmod1,direction = "both")
batisStep2$anova

#initial model selected
```

```{r}
#View selected model
summary(batisPmod1)

#grab residuals for Moran's I testing
P.resid<-resid(batisPmod1)
```
#capture predictions for both models
```{r}
#create objects for loglinear prediction equation
elev<-batis.habY$elevation..m.
sal<-batis.habY$salinity..psu.
Junc<-batis.habY$Juncus
Bor<-batis.habY$Bor

LLpred<- 0.685392 + 1.995671*elev - 0.006826*sal + 0.039775*Junc + 0.046924*Bor

batis.hab$batisLMpred<-0   
n<-0
for (i in 1:length(batis.hab[,1])) {   #index in the LM productivity estimates to sarc.hab
  test<-batis.hab$logBatis[i]
  if(test > 0 ){ #productivity estimate is zero where not present
    n<-n+1
    
    batis.hab$batisLMpred[i]<-LLpred[n]  
  }
}

#get logistic predictions from model
batis.hab$batisLOGpred<-predict(batisPAmod1,type = "response")

#insert 0 predictions for each value in the salt pan & below the elevation threshold
batis.inhosp$batisLOGpred<-0
batis.inhosp$batisLMpred<-0
```
#conduct spatial autocorrelation correction on both models
```{r}
library(spdep) #library the spatial dependance package

#carry out the Moran's I estimation for both models
PAxy.data<-cbind(batis.hab$easting..m.,batis.hab$northing..m.) 
Pxy.data<-cbind(batis.habY$easting..m.,batis.habY$northing..m.)

PAxy.knn<-knearneigh(PAxy.data,k = 4)
PAxy.nb<-knn2nb(PAxy.knn)

Pxy.knn<-knearneigh(Pxy.data,k = 4)
Pxy.nb<-knn2nb(Pxy.knn)

PA.batis.Moran<-moran.test(PA.resid,nb2listw(PAxy.nb,style ="W"))
P.batis.Moran<-moran.test(P.resid,nb2listw(Pxy.nb,style ="W"))
```

#compute adjusted sample size, standard errors and p values
```{r}
PAbatisNeff<-as.numeric(N.eff(PA.batis.Moran$estimate[1],length(batis.hab[,1]))) #calculate n' for each model using function written above
PbatisNeff<-as.numeric(N.eff(P.batis.Moran$estimate[1],length(batis.habY[,1])))
#n' values added to column 3 & 4 of Table 2

mod.adjuster(batisPAmod1,PAbatisNeff) #adjust each model and print values
mod.adjuster(batisPmod1,PbatisNeff)

#evaluate p values for increases above 0.05
```

#Continuing as directed in the Schwieger R code, may need to amend to reflect updates
```{r}
#bind the two dataframes together, and create a cohesive prediction value column
batis.merge<-rbind(batis.hab,batis.inhosp)

batis.merge$batisPRED<-batis.merge$batisLOGpred*batis.merge$batisLMpred
```
#regress our cohesive predictive value against the observed value
```{r}
batisFmod<-lm(batis.merge$logBatis ~ batis.merge$batisPRED)

summary(batisFmod)

#store R^2 value
batisR2<-summary(batisFmod)$r.squared
batisR2adj<-summary(batisFmod)$adj.r.squared
```
#standardize coefficients
```{r}
batis_coef<-range.std.coef(batisPAmod1,batisPmod1,CNNdata)#calculate final range standardized coefficients
print(batis_coef)
```

